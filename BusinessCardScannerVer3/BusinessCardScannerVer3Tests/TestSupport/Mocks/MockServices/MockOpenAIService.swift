import Foundation
import Combine
@testable import BusinessCardScannerVer3

/// Mock OpenAI æœå‹™ï¼Œç”¨æ–¼æ¸¬è©¦ AI åŠŸèƒ½
final class MockOpenAIService: OpenAIServiceProtocol {
    
    // MARK: - Mock Configuration
    
    /// æ˜¯å¦æ¨¡æ“¬æˆåŠŸå›æ‡‰
    var shouldSucceed: Bool = true
    
    /// æ¨¡æ“¬éŒ¯èª¤
    var mockError: Error = MockError.networkUnavailable
    
    /// å›æ‡‰å»¶é²ï¼ˆç§’ï¼‰
    var responseDelay: TimeInterval = 0.5
    
    /// æ˜¯å¦æœ‰æœ‰æ•ˆ API Key
    var hasValidKey: Bool = true
    
    /// Mock Token ä½¿ç”¨é‡
    var mockTokenUsage: TokenUsage = TokenUsage(
        promptTokens: 150,
        completionTokens: 80,
        totalTokens: 230
    )
    
    // MARK: - Mock Response Data
    
    /// é è¨­ Mock AI å›æ‡‰
    var mockAIResponse: AIResponse = AIResponse(
        id: "chatcmpl-test123",
        model: "gpt-3.5-turbo",
        choices: [
            AIResponse.Choice(
                message: AIResponse.Message(
                    role: "assistant",
                    content: """
                    {
                        "name": "ç‹å¤§æ˜",
                        "namePhonetic": "Wang Da Ming",
                        "company": "ABCç§‘æŠ€å…¬å¸",
                        "jobTitle": "ç”¢å“ç¶“ç†",
                        "department": "ç”¢å“éƒ¨",
                        "phone": "02-1234-5678",
                        "mobile": "0912-345-678",
                        "email": "wang@abc.com",
                        "website": "www.abc.com",
                        "address": "å°åŒ—å¸‚ä¿¡ç¾©å€ä¿¡ç¾©è·¯äº”æ®µ7è™Ÿ",
                        "confidence": 0.92
                    }
                    """
                ),
                finishReason: "stop"
            )
        ],
        usage: TokenUsage(promptTokens: 150, completionTokens: 80, totalTokens: 230)
    )
    
    /// ä¸åŒå ´æ™¯çš„ Mock å›æ‡‰
    var scenarioResponses: [String: AIResponse] = [:]
    
    // MARK: - Test Scenarios Configuration
    
    /// ç¶²è·¯éŒ¯èª¤å ´æ™¯
    var networkErrorScenarios: [Error] = [
        MockError.networkUnavailable,
        NSError(domain: NSURLErrorDomain, code: NSURLErrorTimedOut, userInfo: nil),
        NSError(domain: NSURLErrorDomain, code: NSURLErrorNotConnectedToInternet, userInfo: nil)
    ]
    
    /// API éŒ¯èª¤å ´æ™¯
    var apiErrorScenarios: [Error] = [
        MockError.quotaExceeded,
        NSError(domain: "OpenAI", code: 401, userInfo: [NSLocalizedDescriptionKey: "Invalid API key"]),
        NSError(domain: "OpenAI", code: 429, userInfo: [NSLocalizedDescriptionKey: "Rate limit exceeded"])
    ]
    
    // MARK: - Analytics
    
    private(set) var processCallCount: Int = 0
    private(set) var lastOCRText: String?
    private(set) var lastImageData: Data?
    private(set) var responseTimes: [TimeInterval] = []
    private(set) var totalTokensUsed: Int = 0
    
    // MARK: - OpenAIServiceProtocol Implementation
    
    var tokenUsage: TokenUsage {
        return mockTokenUsage
    }
    
    func processCard(ocrText: String, imageData: Data?) -> AnyPublisher<AIResponse, Error> {
        processCallCount += 1
        lastOCRText = ocrText
        lastImageData = imageData
        
        let startTime = Date()
        
        return Future<AIResponse, Error> { [weak self] promise in
            guard let self = self else {
                promise(.failure(MockError.serviceUnavailable))
                return
            }
            
            DispatchQueue.global(qos: .userInitiated).asyncAfter(deadline: .now() + self.responseDelay) {
                let processingTime = Date().timeIntervalSince(startTime)
                self.responseTimes.append(processingTime)
                
                if self.shouldSucceed {
                    // æ›´æ–° Token ä½¿ç”¨çµ±è¨ˆ
                    self.totalTokensUsed += self.mockTokenUsage.totalTokens
                    
                    // æ ¹æ“šè¼¸å…¥èª¿æ•´å›æ‡‰
                    let response = self.generateResponseForInput(ocrText)
                    promise(.success(response))
                } else {
                    promise(.failure(self.mockError))
                }
            }
        }
        .eraseToAnyPublisher()
    }
    
    func hasValidAPIKey() -> Bool {
        return hasValidKey
    }
    
    // MARK: - Test Helpers
    
    /// é‡ç½® Mock ç‹€æ…‹
    func reset() {
        shouldSucceed = true
        mockError = MockError.networkUnavailable
        responseDelay = 0.5
        hasValidKey = true
        
        // é‡ç½®åˆ†ææ•¸æ“š
        processCallCount = 0
        lastOCRText = nil
        lastImageData = nil
        responseTimes.removeAll()
        totalTokensUsed = 0
        
        // é‡ç½®å ´æ™¯å›æ‡‰
        scenarioResponses.removeAll()
        setupDefaultScenarios()
    }
    
    /// è¨­å®šé è¨­å ´æ™¯
    private func setupDefaultScenarios() {
        // ä¸­æ–‡åç‰‡å ´æ™¯
        scenarioResponses["chinese"] = AIResponse(
            id: "chatcmpl-chinese123",
            model: "gpt-3.5-turbo",
            choices: [
                AIResponse.Choice(
                    message: AIResponse.Message(
                        role: "assistant",
                        content: """
                        {
                            "name": "ç‹å¤§æ˜",
                            "namePhonetic": "Wang Da Ming",
                            "company": "ABCç§‘æŠ€å…¬å¸",
                            "jobTitle": "ç”¢å“ç¶“ç†",
                            "phone": "02-1234-5678",
                            "mobile": "0912-345-678",
                            "email": "wang@abc.com",
                            "confidence": 0.92
                        }
                        """
                    ),
                    finishReason: "stop"
                )
            ],
            usage: mockTokenUsage
        )
        
        // è‹±æ–‡åç‰‡å ´æ™¯
        scenarioResponses["english"] = AIResponse(
            id: "chatcmpl-english123",
            model: "gpt-3.5-turbo",
            choices: [
                AIResponse.Choice(
                    message: AIResponse.Message(
                        role: "assistant",
                        content: """
                        {
                            "name": "John Smith",
                            "company": "ABC Technology Inc.",
                            "jobTitle": "Product Manager",
                            "phone": "+1-555-0123",
                            "mobile": "+1-555-0124",
                            "email": "john@abc.com",
                            "website": "www.abc-tech.com",
                            "confidence": 0.95
                        }
                        """
                    ),
                    finishReason: "stop"
                )
            ],
            usage: mockTokenUsage
        )
        
        // è¤‡é›œç‰ˆé¢å ´æ™¯
        scenarioResponses["complex"] = AIResponse(
            id: "chatcmpl-complex123",
            model: "gpt-3.5-turbo",
            choices: [
                AIResponse.Choice(
                    message: AIResponse.Message(
                        role: "assistant",
                        content: """
                        {
                            "name": "æå°è¯",
                            "company": "XYZè¨­è¨ˆå·¥ä½œå®¤",
                            "jobTitle": "å‰µæ„ç¸½ç›£",
                            "department": "è¨­è¨ˆéƒ¨",
                            "phone": "02-8765-4321",
                            "mobile": "0987-654-321",
                            "email": "lee@xyz.com",
                            "website": "www.xyz-design.com",
                            "address": "å°åŒ—å¸‚å¤§å®‰å€æ•¦åŒ–å—è·¯äºŒæ®µ123è™Ÿ8æ¨“",
                            "confidence": 0.88
                        }
                        """
                    ),
                    finishReason: "stop"
                )
            ],
            usage: TokenUsage(promptTokens: 200, completionTokens: 120, totalTokens: 320)
        )
    }
    
    /// è¨­å®šç‰¹å®šå ´æ™¯å›æ‡‰
    func setScenarioResponse(_ scenario: String, response: AIResponse) {
        scenarioResponses[scenario] = response
    }
    
    /// è¨­å®šç¶²è·¯éŒ¯èª¤å ´æ™¯
    func setNetworkErrorScenario() {
        shouldSucceed = false
        mockError = networkErrorScenarios.randomElement() ?? MockError.networkUnavailable
    }
    
    /// è¨­å®š API éŒ¯èª¤å ´æ™¯
    func setAPIErrorScenario() {
        shouldSucceed = false
        mockError = apiErrorScenarios.randomElement() ?? MockError.quotaExceeded
    }
    
    /// è¨­å®šç„¡æ•ˆ API Key å ´æ™¯
    func setInvalidAPIKeyScenario() {
        hasValidKey = false
        shouldSucceed = false
        mockError = NSError(domain: "OpenAI", code: 401, userInfo: [
            NSLocalizedDescriptionKey: "Invalid API key provided"
        ])
    }
    
    /// è¨­å®šé…é¡è¶…é™å ´æ™¯
    func setQuotaExceededScenario() {
        shouldSucceed = false
        mockError = MockError.quotaExceeded
    }
    
    /// è¨­å®šæ…¢é€Ÿå›æ‡‰å ´æ™¯
    func setSlowResponseScenario() {
        responseDelay = 5.0
    }
    
    /// è¨­å®šé«˜å“è³ªè§£æå ´æ™¯
    func setHighQualityParsingScenario() {
        mockTokenUsage = TokenUsage(promptTokens: 180, completionTokens: 100, totalTokens: 280)
        mockAIResponse = AIResponse(
            id: "chatcmpl-hq123",
            model: "gpt-3.5-turbo",
            choices: [
                AIResponse.Choice(
                    message: AIResponse.Message(
                        role: "assistant",
                        content: """
                        {
                            "name": "ç‹å¤§æ˜",
                            "namePhonetic": "Wang Da Ming",
                            "company": "ABCç§‘æŠ€å…¬å¸",
                            "jobTitle": "ç”¢å“ç¶“ç†",
                            "department": "ç”¢å“éƒ¨",
                            "phone": "02-1234-5678",
                            "mobile": "0912-345-678",
                            "email": "wang@abc.com",
                            "website": "www.abc.com",
                            "address": "å°åŒ—å¸‚ä¿¡ç¾©å€ä¿¡ç¾©è·¯äº”æ®µ7è™Ÿ",
                            "confidence": 0.98
                        }
                        """
                    ),
                    finishReason: "stop"
                )
            ],
            usage: mockTokenUsage
        )
    }
    
    /// è¨­å®šä½å“è³ªè§£æå ´æ™¯
    func setLowQualityParsingScenario() {
        mockAIResponse = AIResponse(
            id: "chatcmpl-lq123",
            model: "gpt-3.5-turbo",
            choices: [
                AIResponse.Choice(
                    message: AIResponse.Message(
                        role: "assistant",
                        content: """
                        {
                            "name": "ä¸ç¢ºå®š",
                            "company": "ç„¡æ³•è­˜åˆ¥",
                            "confidence": 0.45
                        }
                        """
                    ),
                    finishReason: "stop"
                )
            ],
            usage: TokenUsage(promptTokens: 220, completionTokens: 60, totalTokens: 280)
        )
    }
    
    // MARK: - Private Helpers
    
    private func generateResponseForInput(_ ocrText: String) -> AIResponse {
        // æ ¹æ“š OCR æ–‡å­—å…§å®¹æ™ºæ…§é¸æ“‡å ´æ™¯
        let lowercaseText = ocrText.lowercased()
        
        if lowercaseText.contains("john") || lowercaseText.contains("smith") {
            return scenarioResponses["english"] ?? mockAIResponse
        } else if lowercaseText.contains("æå°è¯") || lowercaseText.contains("xyz") {
            return scenarioResponses["complex"] ?? mockAIResponse
        } else if lowercaseText.contains("ç‹") || lowercaseText.contains("abc") {
            return scenarioResponses["chinese"] ?? mockAIResponse
        }
        
        // é è¨­å›æ‡‰
        return mockAIResponse
    }
    
    // MARK: - Test Verification
    
    /// é©—è­‰ processCard å‘¼å«æ¬¡æ•¸
    func verifyProcessCalled(times expectedTimes: Int) -> Bool {
        return processCallCount == expectedTimes
    }
    
    /// é©—è­‰æœ€å¾Œè™•ç†çš„ OCR æ–‡å­—
    func verifyLastOCRText(contains expectedText: String) -> Bool {
        guard let lastText = lastOCRText else { return false }
        return lastText.contains(expectedText)
    }
    
    /// é©—è­‰å›æ‡‰æ™‚é–“
    func verifyResponseTime(within expectedRange: ClosedRange<TimeInterval>) -> Bool {
        guard let lastTime = responseTimes.last else { return false }
        return expectedRange.contains(lastTime)
    }
    
    /// å–å¾—å¹³å‡å›æ‡‰æ™‚é–“
    func averageResponseTime() -> TimeInterval {
        guard !responseTimes.isEmpty else { return 0.0 }
        return responseTimes.reduce(0, +) / Double(responseTimes.count)
    }
    
    /// å–å¾— Token ä½¿ç”¨çµ±è¨ˆ
    func getTokenUsageStats() -> (total: Int, average: Double, calls: Int) {
        let averagePerCall = processCallCount > 0 ? Double(totalTokensUsed) / Double(processCallCount) : 0.0
        return (total: totalTokensUsed, average: averagePerCall, calls: processCallCount)
    }
    
    /// é©—è­‰æœ€å¾Œè™•ç†æ˜¯å¦åŒ…å«åœ–ç‰‡è³‡æ–™
    func verifyLastRequestHadImageData() -> Bool {
        return lastImageData != nil
    }
    
    // MARK: - Debug Helpers
    
    /// å°å‡ºæ¸¬è©¦çµ±è¨ˆè³‡è¨Š
    func printTestStats() {
        print("ğŸ¤– MockOpenAIService æ¸¬è©¦çµ±è¨ˆï¼š")
        print("   å‘¼å«æ¬¡æ•¸: \(processCallCount)")
        print("   å¹³å‡å›æ‡‰æ™‚é–“: \(String(format: "%.3f", averageResponseTime()))s")
        print("   ç¸½ Token ä½¿ç”¨é‡: \(totalTokensUsed)")
        print("   æ˜¯å¦æˆåŠŸ: \(shouldSucceed)")
        print("   æœ‰æ•ˆ API Key: \(hasValidKey)")
        if let lastText = lastOCRText {
            print("   æœ€å¾Œè™•ç†æ–‡å­—é•·åº¦: \(lastText.count) å­—ç¬¦")
        }
    }
    
    /// æ¨¡æ“¬ Token æˆæœ¬è¨ˆç®—
    func calculateEstimatedCost() -> Double {
        // å‡è¨­æ¯ 1000 tokens æˆæœ¬ $0.002
        let costPer1000Tokens = 0.002
        return Double(totalTokensUsed) / 1000.0 * costPer1000Tokens
    }
}